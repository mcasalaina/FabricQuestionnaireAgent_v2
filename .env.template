# Azure AI Foundry Configuration
# Copy this file to .env and fill in your actual values

# Azure OpenAI Model Deployment
# The name of your deployed model in Azure AI Foundry (e.g., gpt-4, gpt-35-turbo)
AZURE_OPENAI_MODEL_DEPLOYMENT=your-model-deployment-name

# Azure AI Foundry Project Endpoint
# Get this from Azure AI Foundry Portal > Project Overview > Project Details
# Format: https://your-project-resource.services.ai.azure.com/api/projects/your-project-name
AZURE_OPENAI_ENDPOINT=https://your-project-resource.services.ai.azure.com/api/projects/your-project-name

# Bing Search Configuration
# The connection name for Bing Search in your Azure AI Foundry project
# Both variables should typically have the same value
BING_GROUNDING_NAME=your-bing-connection-name
BING_CONNECTION_ID=your-bing-connection-name

# Application Insights Configuration
# Get this from Azure Portal > Application Insights > Overview > Connection String
# Required for Azure AI Foundry tracing and monitoring
# Format: InstrumentationKey=xxx;IngestionEndpoint=https://xxx.in.applicationinsights.azure.com/;LiveEndpoint=https://xxx.livediagnostics.monitor.azure.com/;ApplicationId=xxx
APPLICATIONINSIGHTS_CONNECTION_STRING=your-application-insights-connection-string

# Tracing Configuration
# Set to 'true' to capture AI prompts and responses in traces (may contain personal data)
# Set to 'false' for production if you want to exclude content from traces
AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED=true

# The Fabric connection name to use for answering questions
FABRIC_CONNECTION_ID=your-fabric-connection-name